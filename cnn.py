import torch
from torch import nn
from d2l import torch as d2l

'''
    å¹³ç§»ä¸å˜æ€§ï¼ˆtranslation invarianceï¼‰ï¼šä¸ç®¡æ£€æµ‹å¯¹è±¡å‡ºç°åœ¨å›¾åƒä¸­çš„å“ªä¸ªä½ç½®ï¼Œç¥ç»ç½‘ç»œçš„å‰é¢å‡ å±‚åº”è¯¥å¯¹ç›¸åŒçš„å›¾åƒåŒºåŸŸå…·æœ‰ç›¸ä¼¼çš„ååº”ï¼Œå³ä¸ºâ€œå¹³ç§»ä¸å˜æ€§â€ã€‚
    å±€éƒ¨æ€§ï¼ˆlocalityï¼‰ï¼šç¥ç»ç½‘ç»œçš„å‰é¢å‡ å±‚åº”è¯¥åªæ¢ç´¢è¾“å…¥å›¾åƒä¸­çš„å±€éƒ¨åŒºåŸŸï¼Œè€Œä¸è¿‡åº¦åœ¨æ„å›¾åƒä¸­ç›¸éš”è¾ƒè¿œåŒºåŸŸçš„å…³ç³»ï¼Œè¿™å°±æ˜¯â€œå±€éƒ¨æ€§â€åŸåˆ™ã€‚æœ€ç»ˆï¼Œå¯ä»¥èšåˆè¿™äº›å±€éƒ¨ç‰¹å¾ï¼Œä»¥åœ¨æ•´ä¸ªå›¾åƒçº§åˆ«è¿›è¡Œé¢„æµ‹ã€‚
'''


# è¾“å…¥å¤§å° nâ„Ã—nğ‘¤ ,æ ¸å¤§å° kâ„Ã—kğ‘¤ ,æ­¥é•¿1çš„æ—¶å€™è¾“å‡ºå¤§å°(nâ„âˆ’kâ„+1)Ã—(nğ‘¤âˆ’kğ‘¤+1)
def corr2d(X, K):  # @save
    """è®¡ç®—äºŒç»´äº’ç›¸å…³è¿ç®—"""
    h, w = K.shape
    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))
    for i in range(Y.shape[0]):
        for j in range(Y.shape[1]):
            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()
    return Y


# ç®€å•å·ç§¯å±‚å®ç°,æˆ‘ä»¬å°†å¸¦æœ‰â„Ã—ğ‘¤å·ç§¯æ ¸çš„å·ç§¯å±‚ç§°ä¸ºâ„Ã—ğ‘¤å·ç§¯å±‚ã€‚
class Conv2D(nn.Module):
    def __init__(self, kernel_size):
        super().__init__()
        self.weight = nn.Parameter(torch.rand(kernel_size))
        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        return corr2d(x, self.weight) + self.bias


# å°caseï¼Œå›¾åƒçš„å‚ç›´è¾¹ç¼˜æ£€æµ‹,1ç™½è‰²ï¼Œ0é»‘è‰²
X = torch.ones((6, 8))  # å›¾åƒ
X[:, 2:6] = 0
K = torch.tensor([[1.0, -1.0]])  # å·ç§¯æ ¸
Y = corr2d(X, K)  # è¾“å‡ºYä¸­çš„1ä»£è¡¨ä»ç™½è‰²åˆ°é»‘è‰²çš„è¾¹ç¼˜ï¼Œ-1ä»£è¡¨ä»é»‘è‰²åˆ°ç™½è‰²çš„è¾¹ç¼˜

# å­¦ä¹ å·ç§¯æ ¸
# æ„é€ ä¸€ä¸ªäºŒç»´å·ç§¯å±‚ï¼Œå®ƒå…·æœ‰1ä¸ªè¾“å‡ºé€šé“å’Œå½¢çŠ¶ä¸ºï¼ˆ1ï¼Œ2ï¼‰çš„å·ç§¯æ ¸
conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)

# è¿™ä¸ªäºŒç»´å·ç§¯å±‚ä½¿ç”¨å››ç»´è¾“å…¥å’Œè¾“å‡ºæ ¼å¼ï¼ˆæ‰¹é‡å¤§å°ã€é€šé“ã€é«˜åº¦ã€å®½åº¦ï¼‰ï¼Œ
# å…¶ä¸­æ‰¹é‡å¤§å°å’Œé€šé“æ•°éƒ½ä¸º1
X = X.reshape((1, 1, 6, 8))
Y = Y.reshape((1, 1, 6, 7))
lr = 3e-2  # å­¦ä¹ ç‡
# æ‰€å­¦çš„å·ç§¯æ ¸çš„æƒé‡å¼ é‡ conv2d.weight.data.reshape((1, 2)) æœ€åç»“æœå’Œä¸Šé¢çš„Kå¾ˆæ¥è¿‘
for i in range(10):
    Y_hat = conv2d(X)
    l = (Y_hat - Y) ** 2
    conv2d.zero_grad()
    l.sum().backward()
    # è¿­ä»£å·ç§¯æ ¸
    conv2d.weight.data[:] -= lr * conv2d.weight.grad
    if (i + 1) % 2 == 0:
        print(f'epoch {i + 1}, loss {l.sum():.3f}')


# ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªè®¡ç®—å·ç§¯å±‚çš„å‡½æ•°ã€‚
# æ­¤å‡½æ•°åˆå§‹åŒ–å·ç§¯å±‚æƒé‡ï¼Œå¹¶å¯¹è¾“å…¥å’Œè¾“å‡ºæé«˜å’Œç¼©å‡ç›¸åº”çš„ç»´æ•°
def comp_conv2d(conv2d, X):
    # è¿™é‡Œçš„ï¼ˆ1ï¼Œ1ï¼‰è¡¨ç¤ºæ‰¹é‡å¤§å°å’Œé€šé“æ•°éƒ½æ˜¯1
    X = X.reshape((1, 1) + X.shape)
    Y = conv2d(X)
    # çœç•¥å‰ä¸¤ä¸ªç»´åº¦ï¼šæ‰¹é‡å¤§å°å’Œé€šé“
    return Y.reshape(Y.shape[2:])


# è¯·æ³¨æ„ï¼Œè¿™é‡Œæ¯è¾¹éƒ½å¡«å……äº†1è¡Œæˆ–1åˆ—ï¼Œå› æ­¤æ€»å…±æ·»åŠ äº†2è¡Œæˆ–2åˆ—
conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1) # stride=2 æ­¥å¹…ä¸º2
X = torch.rand(size=(8, 8))
comp_conv2d(conv2d, X).shape  # è¾“å‡ºä¾ç„¶æ˜¯(8,8)
conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4)) # pad é«˜å®½ï¼Œæ­¥å¹… é«˜å®½
